{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------Import Libraries---------------------------------#\n",
    "import pandas as pd # importing all necessary Libraries \n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------Reading file-------------------------------------#\n",
    "\n",
    "df = pd.read_csv(r\"seismic_bumps1.csv\")   # Reading seismic_bumps1.csv file using panda\n",
    "attributes = list(df.head(0)) # list of all attributes\n",
    "df.drop(attributes[8:16],axis=1,inplace=True) # droping unnecessary attributes\n",
    "attr = list(df.head(0)) # list of all attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------Spliting Data or Data Preprocessing-------------------------------------#\n",
    "\n",
    "gkk = df.groupby('class') # grouping on the basis of class\n",
    "[X_train ,X_test, X_label_train, X_label_test] = [pd.DataFrame() # initialising all variables with empty dataframe\n",
    "                    ,pd.DataFrame(),pd.DataFrame(),pd.DataFrame()] \n",
    "\n",
    "for i,j in gkk:\n",
    "    [a_train, b_test, a_label_train, b_label_test]=train_test_split(j.copy(),\n",
    "        j['class'], test_size=0.3, random_state=42,shuffle=True) # spliting data 70% train and 30% test of each class\n",
    "    \n",
    "    [X_train, X_test, X_label_train, X_label_test] = [pd.concat([X_train,a_train]), # concatinate the data of each class\n",
    "        pd.concat([X_test,b_test]),pd.concat([X_label_train,a_label_train]),\n",
    "        pd.concat([X_label_test,b_label_test])]\n",
    " \n",
    "X_test = X_test.drop('class',axis=1)  # test data contain class attribute so drop it\n",
    "X_train.to_csv('seismic-bumps-train.csv',index=False) # saving train data into csv file\n",
    "X_test.to_csv('seismic-bumps-test.csv',index=False) # savind test data into csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------Defining all necessary functions------------------------#\n",
    "\n",
    "def K_NN(k,train_data,test_data): # define K-NN function \n",
    "    model = KNeighborsClassifier(n_neighbors=k) # using K-NN classifier for particular k\n",
    "    model.fit(train_data,X_label_train.values.ravel()) # fitting train data \n",
    "    predicted= model.predict(test_data) # prdicting class\n",
    "    conf_mat = confusion_matrix(X_label_test,predicted)  # forming confusion matrix\n",
    "    accuracy = accuracy_score(X_label_test,predicted) # finding accuracy using accuracy_score function\n",
    "    return accuracy, conf_mat # returning accuracy and confusion matrix\n",
    "\n",
    "def show_confMat_accu(train_data,test_data): # function to showing confusion matrix and accuracy\n",
    "    k_high_accuracy = 1 # variable to find k which has max accuracy\n",
    "    high_accuracy = 0 # variable to find high accuracy\n",
    "    for k in range(1,6,2):\n",
    "        print(\"\\nK = \",k)\n",
    "        accu, conf_mat = K_NN(k,train_data,test_data) # calling K-NN function\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(conf_mat) # printing confusion_matrix\n",
    "        print(\"Accuracy: \",accu) # printing accuracy\n",
    "        if accu > high_accuracy: # finding max accuracy\n",
    "            high_accuracy = accu\n",
    "            k_high_accuracy = k\n",
    "    print(f\"\\nHigh Accuracy is for k = {k_high_accuracy} is {high_accuracy}\")\n",
    "    return high_accuracy # returning high accuracy\n",
    "\n",
    "def min_max_scaling(df,minValue,maxValue,train_data): # function to normalized data\n",
    "    df_norm = df.copy()# copy the dataframe\n",
    "    attr = list(df_norm.head(0)) # list of attributes\n",
    "    for column in attr:  # normalizing data using min-max scaling\n",
    "        min_df = train_data[column].min() # minimum value of train data\n",
    "        max_df = train_data[column].max() # maximum value of test data\n",
    "        df_norm[column] = (((df_norm[column] - min_df) / (max_df - min_df))*(maxValue-minValue))+minValue    \n",
    "    return df_norm # returning normalized data\n",
    "\n",
    "def likelihood(sample,mean,covariance): # defining likelihood function\n",
    "    # calculating exponential factor\n",
    "    expo_part = math.exp((-1/2)*(np.dot(np.dot((sample-mean),np.linalg.inv(covariance)),(sample-mean).transpose())))\n",
    "    # calculating pre-exponential factor\n",
    "    non_exp_part = 1/(((2*math.pi)**(len(mean)/2))*(np.linalg.det(covariance)**0.5))\n",
    "    return non_exp_part*expo_part # reyurning likelihood probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------QUSETION 1-------------------------------------\n",
      "K-nearest neighbour (K-NN) classifier\n",
      "\n",
      "K =  1\n",
      "Confusion Matrix:\n",
      "[[671  54]\n",
      " [ 46   5]]\n",
      "Accuracy:  0.8711340206185567\n",
      "\n",
      "K =  3\n",
      "Confusion Matrix:\n",
      "[[707  18]\n",
      " [ 47   4]]\n",
      "Accuracy:  0.9162371134020618\n",
      "\n",
      "K =  5\n",
      "Confusion Matrix:\n",
      "[[718   7]\n",
      " [ 46   5]]\n",
      "Accuracy:  0.9317010309278351\n",
      "\n",
      "High Accuracy is for k = 5 is 0.9317010309278351\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n-----------------------------------QUSETION 1-------------------------------------\")\n",
    "print(\"K-nearest neighbour (K-NN) classifier\")\n",
    "q1_accu = show_confMat_accu(X_train.iloc[:,:-1],X_test)  # calling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------QUSETION 2-------------------------------------\n",
      "K-nearest neighbour (K-NN) classifier on normalized data\n",
      "\n",
      "K =  1\n",
      "Confusion Matrix:\n",
      "[[678  47]\n",
      " [ 42   9]]\n",
      "Accuracy:  0.8853092783505154\n",
      "\n",
      "K =  3\n",
      "Confusion Matrix:\n",
      "[[705  20]\n",
      " [ 44   7]]\n",
      "Accuracy:  0.9175257731958762\n",
      "\n",
      "K =  5\n",
      "Confusion Matrix:\n",
      "[[718   7]\n",
      " [ 48   3]]\n",
      "Accuracy:  0.9291237113402062\n",
      "\n",
      "High Accuracy is for k = 5 is 0.9291237113402062\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n-----------------------------------QUSETION 2-------------------------------------\")\n",
    "print(\"K-nearest neighbour (K-NN) classifier on normalized data\")\n",
    "normal_train_data = min_max_scaling(X_train.iloc[:,:-1],0,1,X_train.iloc[:,:-1]) # normalizing train data\n",
    "normal_train_data.to_csv('seismic-bumps-train-Normalized.csv',index=False) # saving csv file of train data\n",
    "normal_test_data = min_max_scaling(X_test,0,1,X_train.iloc[:,:-1]) # normalizing test data\n",
    "normal_test_data.to_csv('seismic-bumps-test-Normalized.csv',index=False) # saving csv file of test data\n",
    "q2_accu = show_confMat_accu(normal_train_data,normal_test_data) # calling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------QUSETION 3-------------------------------------\n",
      "Bayes classifier:\n",
      "\n",
      "Confusion Matrix:\n",
      " [[663  62]\n",
      " [ 35  16]]\n",
      "Accuracy: 0.875\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n-----------------------------------QUSETION 3-------------------------------------\")\n",
    "print(\"Bayes classifier:\")\n",
    "gkk = X_train.groupby('class') #grouping data on the basis of class\n",
    "mean = [] # list contaning mean vector of each class \n",
    "covariance = [] # list contain covariance matrix of each class\n",
    "cls_row = [] # list containg length of each class\n",
    "for i,j in gkk:\n",
    "    mean.append(np.array(j.iloc[:,:-1].mean().tolist())) # finding mean vector of the data\n",
    "    covariance.append(np.cov(j.iloc[:,:-1].transpose())) # finding covariance matrix of data\n",
    "    cls_row.append(len(j.iloc[:,1])) # finding number of rows in data\n",
    "predict = [] # list contain prediction of test data\n",
    "for i in X_test.index: # looping over test data\n",
    "    sample = (list(X_test.loc[i]))  # list of tuple\n",
    "    # calculating  Evedience P(x)  \n",
    "    den = (likelihood(sample,mean[0],covariance[0]))*(cls_row[0]/sum(cls_row))+ (likelihood(sample,mean[1],covariance[1])*(cls_row[1]/sum(cls_row)))        \n",
    "    # calculating P(C0/x) i.e posterior probability of class 0\n",
    "    prob_cls0 = (likelihood(sample,mean[0],covariance[0])*(cls_row[0]/sum(cls_row)))/den\n",
    "    # calculating P(C1/x) i.e posterior probability of class 1\n",
    "    prob_cls1 = (likelihood(sample,mean[1],covariance[1])*(cls_row[1]/sum(cls_row)))/den\n",
    "    if prob_cls0 > prob_cls1: # comparing probability and then assigning classs\n",
    "        predict.append(0)\n",
    "    else:\n",
    "        predict.append(1)\n",
    "conf_mat = confusion_matrix(X_label_test,predict) # finding confusion matrix\n",
    "q3_accu = accuracy_score(X_label_test,predict) # finding accuracy of Bay's classifier\n",
    "print(\"\\nConfusion Matrix:\\n\",conf_mat)\n",
    "print(\"Accuracy:\",q3_accu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------QUSETION 4-------------------------------------\n",
      "                         Accuracy\n",
      "                                 \n",
      "K-NN Classifier          0.931701\n",
      "K-NN on normalized data  0.929124\n",
      "Bayes Classifier         0.875000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n-----------------------------------QUSETION 4-------------------------------------\")\n",
    "data = {\"\":['K-NN Classifier','K-NN on normalized data','Bayes Classifier'],\n",
    "        \"Accuracy\":[q1_accu,q2_accu,q3_accu]} # forming dataframe of accuracy of each method\n",
    "data = pd.DataFrame(data)\n",
    "data = data.set_index([\"\"])\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
